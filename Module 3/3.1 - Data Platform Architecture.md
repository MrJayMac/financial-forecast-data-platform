### Data Platform Architecture (Key Points)

**Layers**  
1. **Data Ingestion (Collection Layer)**  
   - Connects to source systems, ingests data in **batch or streaming** mode.  
   - Tracks metadata (e.g., batch size, source).  
   - Tools: Google DataFlow, Apache Kafka, Amazon Kinesis, IBM Streams.  

2. **Data Storage & Integration Layer**  
   - Stores data for both short- and long-term use.  
   - Transforms and merges extracted data.  
   - Needs to be **reliable, scalable, cost-efficient**.  
   - Relational DBs: IBM DB2, SQL Server, MySQL, Oracle, PostgreSQL.  
   - Cloud DBaaS: Amazon RDS, Google Cloud SQL, SQL Azure.  
   - NoSQL: MongoDB, Cassandra, Redis, Neo4J.  
   - Integration tools: Talend, IBM Cloud Pak, SnapLogic, Dell Boomi.  

3. **Data Processing Layer**  
   - Validations, transformations, business logic.  
   - Tasks: Structuring, normalization, denormalization, data cleaning.  
   - Tools: Spreadsheets, OpenRefine, Google DataPrep, Trifacta Wrangler, Python/R libraries, Spark.  

4. **Analysis & User Interface Layer**  
   - Delivers processed data to analysts, data scientists, stakeholders, and apps.  
   - Supports SQL, SQL-like tools (e.g., CQL for Cassandra), APIs, Python/R/Java.  
   - Tools: Tableau, Power BI, Jupyter, IBM Cognos Analytics.  

**Overlay: Data Pipeline Layer**  
- Ensures continuous flow of data using ETL/ELT.  
- Tools: Apache Airflow, Google DataFlow.  

**Key Takeaways**  
- Layers = Ingestion → Storage/Integration → Processing → Analysis/UI.  
- Pipelines connect them all (batch + streaming).  
- Storage + processing can overlap (e.g., RDBMS vs. Hadoop + Spark).  
- Goal: deliver **reliable, scalable, governed data** for analysis and decision-making.  
